{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'윤석열 전 대통령님에 대한 재미있는 농담 하나 알려드릴게요.\\n\\n\"윤석열 전 대통령님이 정치를 하시면서 가장 중요하게 생각하신 것은 국민의 행복입니다. 어느 날, 국민 한 분이 찾아와 \\'대통령님, 제 아이가 아파서 병원에 가야 하는데 택시비가 부족합니다.\\'라고 말했어요. 그러자 윤석열 전 대통령님이 이렇게 말씀하셨습니다.\\n\\n\\'걱정 마세요, 제가 직접 병원까지 태워다 드리겠습니다.\\'\"\\n\\n이렇게 따뜻한 마음으로 국민을 챙기신 덕분에 나라가 더 행복해졌다고 합니다.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic}에 관한 짧은 농담을 생성해줘\")\n",
    "\n",
    "# 여러 버전의 질문으로 변환하는 역할을 맡을 LLM 선언\n",
    "llm = ChatOllama(\n",
    "    model = \"basic_kanana\",\n",
    "    temperature = 0.8\n",
    ")\n",
    "\n",
    "# 출력 파서 설정\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LCEL로 프롬프트 템플릿-LLM-출력 파서 연결하기\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# invoke함수로 chain 실행하기\n",
    "chain.invoke({\"topic\": \"윤석열\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_CODE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
