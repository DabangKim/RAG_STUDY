import streamlit as st
from langchain_ollama import ChatOllama

# ì›¹ í˜ì´ì§€ ì œëª© ì„¤ì •
st.title("ğŸ’¬ Chatbot")

# ì„¸ì…˜ ìƒíƒœ(session_state)ì— 'messages' í‚¤ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
# session_stateëŠ” streamlitì˜ ìƒíƒœ ê´€ë¦¬ ê¸°ëŠ¥ìœ¼ë¡œ, ì‚¬ìš©ìì™€ì˜ ìƒí˜¸ì‘ìš© ê°„ì— ë°ì´í„°ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë¨
# ìµœì´ˆ ì‹¤í–‰ ì‹œ, ì±—ë´‡ì´ ë¨¼ì € ì¸ì‚¬ë§ì„ í•˜ë„ë¡ ê¸°ë³¸ ë©”ì‹œì§€ë¥¼ ì„¸íŒ…í•¨
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"}]

# ì§€ê¸ˆê¹Œì§€ ëŒ€í™” ë‚´ìš©ì„ í™”ë©´ì— ì¶œë ¥
# ì‚¬ìš©ìì™€ ì±—ë´‡ì´ ì£¼ê³ ë°›ì€ ë©”ì‹œì§€ë¥¼ ìˆœì„œëŒ€ë¡œ í™”ë©´ì— ë Œë”ë§
for msg in st.session_state.messages:
    # msg["role"]ì´ 'user' ë˜ëŠ” 'assistant'ì¼ ê²½ìš° ê°ê° ì‚¬ìš©ì/AI ë©”ì‹œì§€ë¡œ ë Œë”ë§ë¨
    # chat_message() í•¨ìˆ˜ëŠ” ì‚¬ìš©ì ë˜ëŠ” AIì˜ ì…ë ¥ê°’ì„ ì±„íŒ… ì»¨í…Œì´ë„ˆì— í‘œì‹œí•˜ëŠ” ì—­í• ì„ í•¨
    st.chat_message(msg["role"]).write(msg["content"])
    # # ë‹¤ë¥¸ ë°©ì‹
    # with st.chat_message(msg["role"]):
    #     st.write(msg["content"]

# ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì •ì˜
# modelì€ ì¹´ì¹´ì˜¤ì˜ 'kanana' ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , temperatureëŠ” ì°½ì˜ì„±(ëœë¤ì„±)ì„ 0.7ë¡œ ì„¤ì •
chat = ChatOllama(model = "basic_kanana", temperature = 0.7)

# ì‚¬ìš©ì ì…ë ¥ì´ ìˆì„ ê²½ìš° (ì…ë ¥ì°½ì—ì„œ ì—”í„°ë¥¼ ëˆŒë €ì„ ë•Œ)
# st.chat_input() í•¨ìˆ˜ì— ì…ë ¥ ê°’ì´ ìˆëŠ” ê²½ìš°, promptë¡œ ì €ì¥í•˜ê³  ì¡°ê±´ì ˆì„ ì´ì–´ë‚˜ê°
if prompt := st.chat_input():
    # ì…ë ¥ëœ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì±„íŒ…ì°½ì— ì¶œë ¥
    st.chat_message("user").write(prompt)

    # AI ëª¨ë¸ì— ì‚¬ìš©ì ì…ë ¥ì„ ì „ë‹¬í•˜ì—¬ ì‘ë‹µ ìƒì„±
    response = chat.invoke(prompt)
    msg = response.content  # ì‘ë‹µ ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ

    # AI ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": msg})
    # AI ë©”ì‹œì§€ë¥¼ ì±„íŒ…ì°½ì— ì¶œë ¥
    st.chat_message("assistant").write(msg)