{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI의 text-embedding-3-small 모델 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"Hi there!\",\n",
    "        \"Oh, hello!\",\n",
    "        \"What's your name?\",\n",
    "        \"My friends call me World\",\n",
    "        \"Hello World!\"\n",
    "    ]\n",
    ")\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PDF 문서 로드\n",
    "loader = PyPDFium2Loader(\"/data/[이슈리포트 2022-2호] 혁신성장 정책금융 동향.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "# PDF 문서를 여러 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 100,\n",
    ")\n",
    "texts = text_splitter.split_documents(pages)\n",
    "\n",
    "# OpenAI 임베딩 모델로 청크들을 임베딩 변환하기\n",
    "embeddings = embeddings_model.embed_documents([i.page_content for i in texts])\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = embeddings_model.embed_documents(   \n",
    "    [\n",
    "        \"안녕하세요\",\n",
    "        \"제 이름은 홍두깨입니다.\",\n",
    "        \"이름이 무엇인가요?\",\n",
    "        \"랭체인은 유용합니다.\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 예시 질문과 답변 임베딩\n",
    "embedded_query_q = embeddings_model.embed_query(\"이 대화에서 언급된 이름은 무엇입니까?\")\n",
    "embedded_query_a = embeddings_model.embed_query(\"이 대화에서 언급된 이름은 홍길동입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "print(cos_sim(embedded_query_q, embedded_query_a))\n",
    "print(cos_sim(embedded_query_a, examples [1]))\n",
    "print(cos_sim(embedded_query_a, examples [3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_CODE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
